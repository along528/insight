{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test a regression model on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Python packages - you may have to pip install sqlalchemy, sqlalchemy_utils, and psycopg2.\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "# Make the graphs a bit prettier, and bigger\n",
    "pd.set_option('display.mpl_style', 'default')\n",
    "\n",
    "# This is necessary to show lots of columns in pandas 0.12. \n",
    "# Not necessary in pandas 0.13.\n",
    "pd.set_option('display.width', 5000) \n",
    "pd.set_option('display.max_columns', 60)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "# The usual preamble\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.color_cycle'] = ['r', 'g', 'b', 'c']\n",
    "plt.rcParams['lines.color'] = 'r'\n",
    "plt.rcParams['figure.figsize'] = (15, 5)\n",
    "\n",
    "import munging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dbname = 'combined_profiling'\n",
    "username = 'along528'\n",
    "pswd = 'password'\n",
    "con = None\n",
    "con = psycopg2.connect(database = dbname, user = username, host='localhost', password=pswd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dbname = 'combined_profiling'\n",
    "username = 'along528'\n",
    "pswd = 'password'\n",
    "## 'engine' is a connection to a database\n",
    "## Here, we're using postgres, but sqlalchemy can connect to other things too.\n",
    "engine = create_engine('postgresql://%s:%s@localhost/%s'%(username,pswd,dbname))\n",
    "print engine.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    sql_query = \"\"\"\n",
    "    SELECT  * FROM traffic_joined_with_features;\n",
    "    \"\"\"\n",
    "    #data = munging.process_df(pd.read_sql_query(sql_query,con))\n",
    "    data = pd.read_sql_query(sql_query,con).drop('index',axis=1)\n",
    "    data = data.set_index('surveyid',drop=True)\n",
    "    data = data[[ 'stops_total', 'searches_total', 'hits_total', 'stops_white', 'searches_white',\n",
    "     'hits_white', 'stops_black', 'searches_black', 'hits_black', \n",
    "     'total',\n",
    "     'urban','rural', \n",
    "     'institutionalized_all', 'institutionalized_adult_all',\n",
    "     'institutionalized_adult_federal_detention_all',\n",
    "     'institutionalized_adult_federal_prison_all',\n",
    "     'institutionalized_adult_state_prison_all',\n",
    "     'institutionalized_adult_local_jail_all',\n",
    "     'institutionalized_juvenile_all',\n",
    "     'institutionalized_white', 'institutionalized_adult_white',\n",
    "     'institutionalized_adult_federal_detention_white',\n",
    "     'institutionalized_adult_federal_prison_white',\n",
    "     'institutionalized_adult_state_prison_white',\n",
    "     'institutionalized_adult_local_jail_white',\n",
    "     'institutionalized_juvenile_white', 'institutionalized_black',\n",
    "     'institutionalized_adult_black', 'institutionalized_adult_federal_detention_black',\n",
    "     'institutionalized_adult_federal_prison_black',\n",
    "     'institutionalized_adult_state_prison_black',\n",
    "     'institutionalized_adult_local_jail_black', \n",
    "     'institutionalized_juvenile_black',\n",
    "     'population_white', 'population_black', 'total_income_estimate_all',\n",
    "     'total_income_estimate_white', 'total_income_estimate_black', 'swnauthemp',\n",
    "     'swnftemp', \n",
    "     'swnptemp', \n",
    "     'civftemp', 'civptemp', 'totftemp', 'totptemp',\n",
    "     'ftreserveswn', 'ptreserveswn', 'ftreserveciv', 'ptreserveciv', 'ftgangoff',\n",
    "     'ptgangoff', 'ftdrugoff', 'ptdrugoff', 'ftterroff', 'pterroff', 'fthumtrfoff',\n",
    "     'pthumtrfoff', 'numrespoff', 'numcpo', 'numsro', 'numpatr', 'numinvst', 'numjail',\n",
    "     'numcrtsec', 'numprocserv', \n",
    "     'opbudget',\n",
    "     'drugforf', 'totacad', 'totfield',\n",
    "     'totinsrv', \n",
    "     'white', 'black', #really doesn't like these variables when dividing\n",
    "     'hispanic', 'asian', 'nathaw', 'amerind', 'multrace',\n",
    "     'unkrace', 'male', 'female', 'totgender', 'chiefmin', 'chiefmax', 'sgtmin',\n",
    "     'sgtmax', 'entrymin', 'entrymax', 'nummrkcars', 'numothmrk', 'numumkcars',\n",
    "     'numothunm', 'numplanes', 'numcopters', 'numboats', 'nummotor', 'numcarcam',\n",
    "     'numfixcam', 'nummobcam', 'population']]\n",
    "    data = data.replace(' ',0)\n",
    "    data = data.replace([np.inf, -np.inf], np.nan)\n",
    "    data = data.dropna()\n",
    "    data = data.apply(lambda x: pd.to_numeric(x))\n",
    "    return data\n",
    "def split_data(data):\n",
    "    test = data.sample(frac=0.2,random_state=20)\n",
    "    val = data[data.index.isin(test_data.index.values.tolist())==False]\n",
    "    return test,val\n",
    "\n",
    "test_data,val_data = split_data(get_data())\n",
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_features(data_tmp):\n",
    "    data = pd.DataFrame(data_tmp)\n",
    "    \n",
    "    \n",
    "    #create rpsi label\n",
    "    num = data['searches_black'] * data['stops_white'] \n",
    "    denom = data['stops_black'] * data['searches_white']\n",
    "    rpsi = num.div(denom)\n",
    "    #drop remaining traffic features\n",
    "    data = data.drop(['stops_total', 'searches_total', 'hits_total', 'stops_white', 'searches_white',\n",
    "                      'hits_white', 'stops_black', 'searches_black', 'hits_black'],axis=1)\n",
    "    #create per_capita features from census population\n",
    "    population = data['total']\n",
    "    per_capita = data.drop('total',axis=1)\n",
    "    per_capita = per_capita.div(population,axis=0)\n",
    "    per_capita.rename(columns=lambda x: x+'_per_capita',inplace=True)\n",
    "    data = pd.concat([data,per_capita],axis=1)\n",
    "    data['total'] = population\n",
    "    \n",
    "    \n",
    "    data['rpsi'] = rpsi\n",
    "    data = data[data['rpsi']<10]\n",
    "    data = data[data['total']>10000]\n",
    "\n",
    "    #build comparison features\n",
    "    data['black_over_white_population_disparity'] = data['population_black'].div(data['population_white'],axis=0).fillna(1)\n",
    "    data['black_over_white_income_disparity'] = data['total_income_estimate_black'].div(data['total_income_estimate_white'],axis=0).fillna(1)\n",
    "    data['black_over_white_population_disparity'] = data['population_black'].div(data['population_white'],axis=0).fillna(1)\n",
    "    data['black_over_white_institutionalized_disparity'] = data['institutionalized_black'].div(data['institutionalized_white'],axis=0).fillna(1)\n",
    "    data['black_over_white_institutionalized_adult_disparity'] = data['institutionalized_adult_black'].div(data['institutionalized_adult_white'],axis=0).fillna(1)\n",
    "    data['black_over_white_institutionalized_adult_federal_detention_disparity'] = data['institutionalized_adult_federal_detention_black'].div(data['institutionalized_adult_federal_detention_white'],axis=0).fillna(1)\n",
    "    data['black_over_white_institutionalized_adult_federal_prison_disparity'] = data['institutionalized_adult_federal_prison_black'].div(data['institutionalized_adult_federal_prison_white'],axis=0).fillna(1)\n",
    "    data['black_over_white_institutionalized_adult_state_prison_disparity'] = data['institutionalized_adult_state_prison_black'].div(data['institutionalized_adult_state_prison_white'],axis=0).fillna(1)\n",
    "    data['black_over_white_institutionalized_adult_local_jail_disparity'] = data['institutionalized_adult_local_jail_black'].div(data['institutionalized_adult_local_jail_white'],axis=0).fillna(1)\n",
    "    data['black_over_white_institutionalized_juvenile_disparity'] = data['institutionalized_juvenile_black'].div(data['institutionalized_juvenile_white'],axis=0).fillna(1)\n",
    "    #compare deomgraphics in police department and in population\n",
    "    for race in ['black','white']:\n",
    "        num = data[race].div(data['swnftemp'],axis=0)\n",
    "        denom = data['population_'+race].div(data['total'],axis=0)\n",
    "        data[race+'_officer_disparity'] = num.div(denom)\n",
    "    data['black_over_white_officer_disparity'] = data['black_officer_disparity'].div(data['white_officer_disparity'])\n",
    "    data = data.replace([np.inf, -np.inf], np.nan)\n",
    "    data = data.dropna()\n",
    "    return data\n",
    "val_data = add_features(val_data)\n",
    "test_data = add_features(test_data)\n",
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#data['rpsi'] = data['rpsi'].astype(int)\n",
    "#data = data[data['rpsi']< 10]\n",
    "#data = data[data['rpsi']> 0]\n",
    "#data = data[data['total']>10000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_data.to_sql('val_data',engine,if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def categorize(rpsi):\n",
    "    if rpsi >=0 and rpsi <=1:\n",
    "        return 0\n",
    "    if rpsi > 1 and rpsi <=2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "X_unscaled = np.array(val_data.drop('rpsi',1))\n",
    "mean = np.mean(X_unscaled, axis=0)\n",
    "std = np.std(X_unscaled, axis=0)\n",
    "X_val = (X_unscaled-mean)/std\n",
    "y_val = np.array(val_data['rpsi'])\n",
    "y_val_cat = np.array(val_data['rpsi'].map(categorize))\n",
    "X_unscaled_test = np.array(test_data.drop('rpsi',1)) \n",
    "X_test = (X_unscaled_test-mean)/std\n",
    "y_test = np.array(test_data['rpsi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_data_scaled = pd.DataFrame(np.c_[X_val,y_val],index=val_data.index,columns=val_data.drop('rpsi',1).columns.tolist()+['rpsi'])\n",
    "val_data_scaled.to_sql('val_data_scaled',engine,if_exists='replace')#print X_val+y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for feature in val_data_scaled.drop('rpsi',1).columns.tolist():\n",
    "    plt.hist(val_data_scaled[feature].tolist(),bins=100)\n",
    "    plt.savefig('images/histos/'+feature+'.png')\n",
    "    plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for feature in val_data.drop('rpsi',1).columns.tolist():\n",
    "    if 'disparity' not in feature: continue\n",
    "    plt.scatter(val_data[feature].tolist(),val_data_scaled['rpsi'].tolist())\n",
    "    plt.savefig('images/scatter/'+feature+'.png')\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.isinf(y_val).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model,cross_validation,metrics,grid_search\n",
    "\n",
    "# Create linear regression object\n",
    "#regr = linear_model.LinearRegression()\n",
    "regr = linear_model.LogisticRegression()\n",
    "n_iter = 10\n",
    "param_grid = {'C':  np.logspace(-5,5,n_iter)}\n",
    "#print param_grid\n",
    "cvmodel = grid_search.RandomizedSearchCV(regr,param_grid,n_iter,cv=5)\n",
    "cvmodel.fit(X_val,y_val_cat)\n",
    "#regr = linear_model.LogisticRegression(C=1.)\n",
    "#regr = linear_model.ElasticNet(alpha=.001, l1_ratio=.8)\n",
    "# Train the model using the training sets\n",
    "#regr.fit(X_val, y_val_cat)\n",
    "#scores = cross_validation.cross_val_score(regr, X_val, y_val, cv=5)\n",
    "#print scores\n",
    "#print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print cvmodel.best_params_\n",
    "print cvmodel.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F = X_val.shape[1]\n",
    "best_features = keep_features = range(F)\n",
    "best_score = np.mean(cross_validation.cross_val_score(cvmodel.best_estimator_, X_val, y_val_cat, cv=5))\n",
    "for i in range(F):\n",
    "    print i,\"of\",F\n",
    "    scores = []\n",
    "    len_best = len(best_features)\n",
    "    for j in range(len_best):\n",
    "        #print \"\\t\",j,\"of\",len_best\n",
    "        keep_features = best_features[:] \n",
    "        del keep_features[j] \n",
    "        scores.append(np.mean( cross_validation.cross_val_score(cvmodel.best_estimator_, X_val[:, keep_features], y_val_cat, cv=5))) \n",
    "    if np.max(scores) >= best_score:\n",
    "        del best_features[np.argmax(scores)]\n",
    "        best_score = np.max(scores) \n",
    "    else:\n",
    "        break\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print best_features\n",
    "print len(best_features)\n",
    "best_feature_names = []\n",
    "for index,column in enumerate(val_data.columns.tolist()):\n",
    "    if index in best_features:\n",
    "        #print column\n",
    "        best_feature_names.append(column)\n",
    "\n",
    "X_unscaled = np.array(val_data[best_feature_names])\n",
    "mean = np.mean(X_unscaled, axis=0)\n",
    "std = np.std(X_unscaled, axis=0)\n",
    "X_val = (X_unscaled-mean)/std\n",
    "y_val = np.array(val_data['rpsi'])\n",
    "y_val_cat = np.array(val_data['rpsi'].map(categorize))\n",
    "X_unscaled_test = np.array(test_data[best_feature_names] )\n",
    "X_test = (X_unscaled_test-mean)/std\n",
    "y_test = np.array(test_data['rpsi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create linear regression object\n",
    "#regr = linear_model.LinearRegression()\n",
    "regr = linear_model.Ridge(alpha=100)\n",
    "#regr = linear_model.LogisticRegression(C=1.)\n",
    "#regr = linear_model.ElasticNet(alpha=.001, l1_ratio=.8)\n",
    "# Train the model using the training sets\n",
    "#regr.fit(X_val, y_val_cat)\n",
    "scores = cross_validation.cross_val_score(regr, X_val, y_val, cv=5)\n",
    "print scores\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The coefficients\n",
    "#print('Coefficients: \\n', regr.coef_)\n",
    "# The mean square error\n",
    "print(\"Residual sum of squares: %.2f\"\n",
    "      % np.mean((regr.predict(X_test) - y_test) ** 2))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % regr.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "plt.scatter(y_test,regr.predict(X_test))\n",
    "#plt.scatter(y_train,regr.predict(X_train))\n",
    "#plt.xlim([0,10])\n",
    "#plt.ylim([0,10])\n",
    "plt.xlabel('Actual RPSI')\n",
    "plt.ylabel('Predicted RPSI')\n",
    "plt.savefig('images/rsquare.png',facecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = regr.predict(X_predict)\n",
    "plt.hist(predictions,bins=50)\n",
    "plt.show()\n",
    "print \"mean =\",predictions.mean(),\"std =\",predictions.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(regr, open( \"pickle/dumb_ridge_regression.p\", \"wb\" ) )\n",
    "pickle.dump(scaler,open(\"pickle/scaler.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
